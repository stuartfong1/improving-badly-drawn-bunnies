{"cells":[{"cell_type":"code","execution_count":54,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-02-08T00:40:12.820634Z","iopub.status.busy":"2024-02-08T00:40:12.820323Z","iopub.status.idle":"2024-02-08T00:40:18.787388Z","shell.execute_reply":"2024-02-08T00:40:18.786390Z","shell.execute_reply.started":"2024-02-08T00:40:12.820610Z"}},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import math\n","import torch\n","from torch import nn\n","from torch.utils.data import DataLoader\n","import torch.nn.functional as F\n","from torch.optim import Adam\n","from tqdm.auto import tqdm\n","import os\n","from datetime import datetime\n","from math import sqrt"]},{"cell_type":"code","execution_count":55,"metadata":{"execution":{"iopub.execute_input":"2024-02-08T00:40:18.789433Z","iopub.status.busy":"2024-02-08T00:40:18.789007Z","iopub.status.idle":"2024-02-08T00:40:20.064977Z","shell.execute_reply":"2024-02-08T00:40:20.064205Z","shell.execute_reply.started":"2024-02-08T00:40:18.789407Z"},"trusted":true},"outputs":[],"source":["# --------- VAE PARAMETERS --------------\n","\n","stroke_dim = 5\n","Nclass = 2\n","\n","# decoder \n","M = 10 # number of normal distributions for output \n","T = 0.1# temperature parameter\n","sqrtT = sqrt(T) # saves computation\n","dec_hidden_dim = 2048 # dimension of cell and hidden states\n","\n","# encoder\n","enc_hidden_dim = 2048 # dimension of cell and hidden states\n","\n","# --------- TRAINING PARAMETERS ----------\n","\n","lr = 2e-3 # Used to be 2e-3 but got NaN gradients\n","batch_size = 2 # batch_size >= 1, used to be 128\n","latent_dim = 128 # Used to be 128\n","n_epochs = 1500 # Used to be 150\n","w_kl = 0.7 # weight for loss calculation, can be tuned if needed\n","anneal_loss = False # True if train using annealed kl loss, False otherwise\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","pretrained = False\n","# --------- DATA LOADING -----------------\n","\n","# Get file path for one class of sketches\n","data_path1 = \"data/axe.npz\"\n","data_path2 = \"data/anvil.npz\"\n","\n","dataset1 = np.load(data_path1, encoding='latin1', allow_pickle=True)\n","dataset2 = np.load(data_path2, encoding='latin1', allow_pickle=True)\n","# data = dataset[\"train\"]\n","Nmax = max(\n","      [len(i) for i in dataset1[\"train\"]] + [len(i) for i in dataset1[\"test\"]]\n","    + [len(i) for i in dataset2[\"train\"]] + [len(i) for i in dataset2[\"test\"]]\n","    )\n"]},{"cell_type":"code","execution_count":56,"metadata":{"execution":{"iopub.execute_input":"2024-02-08T00:40:20.066631Z","iopub.status.busy":"2024-02-08T00:40:20.066145Z","iopub.status.idle":"2024-02-08T00:40:20.075524Z","shell.execute_reply":"2024-02-08T00:40:20.074611Z","shell.execute_reply.started":"2024-02-08T00:40:20.066596Z"},"trusted":true},"outputs":[],"source":["def encode_sketch(sketch,length,N): \n","    ''' \n","    One-hot encode pen state by adding additional columns for pen up and end of stroke.\n","\n","    Parameters: \n","        sketch (ndarray): n*3 array with format (x,y,p1,c), representing sketch data\n","\n","    Returns: \n","        ndarray: n*5 array with format (x,y,p1,p2,p3, c1,...,c_N), where p2 = 1-p1 and p3 is 1 at \n","        end of the sketch, 0 otherwise.\n","    '''\n","\n","    shape = sketch.shape\n","    pen_up = (np.ones(shape[0]) - sketch[:,2]).reshape(shape[0],1)\n","    category = np.zeros((shape[0],N))\n","    \n","    category[:,int(sketch[0][-1])] = 1\n","    \n","    end_stroke = np.zeros((shape[0],1))\n","    end_stroke[length:] = 1 \n","    pen_up[length:] = 0\n","    sketch[:,2][length:] = 0\n","    sketch[-1][2] = 0\n","    \n","    return np.concatenate((sketch[:,:-1],pen_up,end_stroke,category),axis=1)"]},{"cell_type":"code","execution_count":57,"metadata":{"execution":{"iopub.execute_input":"2024-02-08T00:40:20.077743Z","iopub.status.busy":"2024-02-08T00:40:20.077476Z","iopub.status.idle":"2024-02-08T00:40:20.092433Z","shell.execute_reply":"2024-02-08T00:40:20.091694Z","shell.execute_reply.started":"2024-02-08T00:40:20.077715Z"},"trusted":true},"outputs":[],"source":["def encode_dataset1(data,lengths):\n","    \"\"\"\n","    Encode pen states by creating a new array of sketch data.\n","    \n","    Parameters:\n","        data (iterable): object containing data for each sketch\n","        \n","    Returns:\n","        ndarray: object array containing encoded data for each sketch\n","    \"\"\"\n","    # new_data = np.empty(data.size,dtype=object)\n","    new_data = np.empty((data.shape[0], data.shape[1], stroke_dim+Nclass), dtype=object)\n","\n","    for i, sketch in enumerate(data):\n","        new_data[i] = encode_sketch(sketch,lengths[i],Nclass)\n","\n","    return new_data"]},{"cell_type":"code","execution_count":58,"metadata":{"execution":{"iopub.execute_input":"2024-02-08T00:40:20.093695Z","iopub.status.busy":"2024-02-08T00:40:20.093423Z","iopub.status.idle":"2024-02-08T00:40:20.103508Z","shell.execute_reply":"2024-02-08T00:40:20.102699Z","shell.execute_reply.started":"2024-02-08T00:40:20.093673Z"},"trusted":true},"outputs":[],"source":["class SketchesDataset():\n","    def __init__(self, datasets, mode, transform=None):\n","        \"\"\"\n","        data_path: The path to the data\n","        mode: Either 'train' or 'test'\n","        \"\"\"\n","        # data_path is path to one of the npz files\n","        # transform is not currently functional\n","        self.transform = transform\n","        self.mode = mode\n","        self.data_set = []\n","        for i, dataset in enumerate(datasets):\n","            dataset = dataset[mode]\n","            dataset = normalize_data(dataset)\n","            for j, sketch in enumerate(dataset):\n","                sketch_class = np.full((len(sketch), 1), i)\n","                sketch = np.concatenate([sketch, sketch_class], 1)\n","                self.data_set.append(sketch)\n","\n","    def __len__(self):\n","        return len(self.data_set)\n","\n","    def __getitem__(self, idx):\n","        sketch = self.data_set[idx]\n","        if self.transform:\n","            sketch, length = self.transform(sketch)\n","        return sketch, length"]},{"cell_type":"code","execution_count":59,"metadata":{"execution":{"iopub.execute_input":"2024-02-08T00:40:20.104751Z","iopub.status.busy":"2024-02-08T00:40:20.104501Z","iopub.status.idle":"2024-02-08T00:40:20.117636Z","shell.execute_reply":"2024-02-08T00:40:20.116824Z","shell.execute_reply.started":"2024-02-08T00:40:20.104730Z"},"trusted":true},"outputs":[],"source":["def normalize_data(data):\n","\n","    total_length = 0\n","    \n","\n","    for element in data:\n","        total_length += (len(element))\n","\n","\n","    coordinate_list = np.empty((total_length,2))\n","\n","    i = 0\n","\n","    for element in data:\n","        coordinate_list[i:i+len(element),:] = element[:,0:2]\n","        i+=len(element)\n","\n","    data_std = np.std(coordinate_list)\n","\n","    for i, element in enumerate(data):\n","        data[i] = data[i].astype(np.float32)\n","        data[i][:,0:2] = element[:,0:2].astype(np.float32)/data_std\n","    \n","    return data\n"]},{"cell_type":"code","execution_count":60,"metadata":{"execution":{"iopub.execute_input":"2024-02-08T00:40:20.119006Z","iopub.status.busy":"2024-02-08T00:40:20.118721Z","iopub.status.idle":"2024-02-08T00:40:20.127595Z","shell.execute_reply":"2024-02-08T00:40:20.126790Z","shell.execute_reply.started":"2024-02-08T00:40:20.118983Z"},"trusted":true},"outputs":[],"source":["def display_encoded_image(image):\n","    \"\"\"\n","    For some image tensor, draw the image using matplotlib.\n","\n","    Parameters:\n","        - image: some [n*5] tensor representing a sketch.\n","    Returns:\n","        - none\n","    \"\"\"\n","    #Xplot and Yplot are array of points that will be plotted\n","    Xplot = [0]\n","    Yplot = [0]\n","    #Keeps track of the current point that is being drawn\n","    xpos = 0\n","    ypos = 0\n","    #For loop to go through data and plot points\n","    i=0\n","    for i in range(len(image)):\n","        xpos += float(image[i,0])\n","        ypos += float(image[i,1])\n","        Xplot.append(-xpos)\n","        Yplot.append(-ypos)\n","        if image[i,3] == 0:\n","            plt.plot(Xplot, Yplot,color='black')\n","            Xplot.clear()\n","            Yplot.clear()\n","        # elif image[i, 4] == 1:\n","    plt.show()"]},{"cell_type":"code","execution_count":61,"metadata":{"execution":{"iopub.execute_input":"2024-02-08T00:40:20.129284Z","iopub.status.busy":"2024-02-08T00:40:20.128657Z","iopub.status.idle":"2024-02-08T00:40:20.140429Z","shell.execute_reply":"2024-02-08T00:40:20.139609Z","shell.execute_reply.started":"2024-02-08T00:40:20.129259Z"},"trusted":true},"outputs":[],"source":["def kl_loss(sigma_hat, mu):\n","    # torch.sum is added to sum over all the dimensions of the vectors\n","    return (-0.5 / (latent_dim * batch_size)) * torch.sum(1 + sigma_hat - torch.square(mu) - torch.exp(sigma_hat))"]},{"cell_type":"code","execution_count":62,"metadata":{"execution":{"iopub.execute_input":"2024-02-08T00:40:20.141639Z","iopub.status.busy":"2024-02-08T00:40:20.141405Z","iopub.status.idle":"2024-02-08T00:40:20.151079Z","shell.execute_reply":"2024-02-08T00:40:20.150254Z","shell.execute_reply.started":"2024-02-08T00:40:20.141619Z"},"trusted":true},"outputs":[],"source":["def anneal_kl_loss(num_training_steps, reconstruction_loss, kl_loss):\n","    # Hyperparameters\n","    n_min = 0.01  # Starting Value from paper\n","    R = 0.9995  # R is a term close to but less than 1.\n","    KL_min = 0.1 # Value from paper (needs to be between 0.1 and 0.5)\n","\n","    # Initialize\n","    n_step = n_min\n","    total_loss = 0\n","\n","    # Training loop\n","    for step in range(num_training_steps):\n","        # Calculate n_step\n","        n_step = 1 - (1 - n_min) * R**step\n","\n","        # Calculate the total weighted loss\n","        step_loss = reconstruction_loss + w_kl * n_step * max(kl_loss, KL_min)\n","        total_loss += step_loss\n","\n","    return total_loss"]},{"cell_type":"code","execution_count":63,"metadata":{"execution":{"iopub.execute_input":"2024-02-08T00:40:20.154501Z","iopub.status.busy":"2024-02-08T00:40:20.154251Z","iopub.status.idle":"2024-02-08T00:40:20.160897Z","shell.execute_reply":"2024-02-08T00:40:20.160083Z","shell.execute_reply.started":"2024-02-08T00:40:20.154479Z"},"trusted":true},"outputs":[],"source":["def make_image(image):\n","    length = len(image)\n","    new_image = np.zeros((Nmax, 3+Nclass-1))\n","    new_image[:len(image), :] = image[:len(image), :] # copy over values\n","\n","    encoded_strokes = np.stack(encode_dataset1(np.array([new_image]),[length]), 1) # don't forget to stack input along dim = 1\n","    batch = torch.from_numpy(encoded_strokes.astype(float))\n","    return batch, torch.tensor(length)"]},{"cell_type":"code","execution_count":64,"metadata":{"execution":{"iopub.execute_input":"2024-02-08T00:40:20.162379Z","iopub.status.busy":"2024-02-08T00:40:20.162060Z","iopub.status.idle":"2024-02-08T00:40:20.170854Z","shell.execute_reply":"2024-02-08T00:40:20.170095Z","shell.execute_reply.started":"2024-02-08T00:40:20.162345Z"},"trusted":true},"outputs":[],"source":["def make_batch(size=batch_size):\n","    \"\"\"\n","    Using the data created earlier in the code and a given batch size, randomly fetch\n","    that many images and return them + their lengths.\n","\n","    Parameters:\n","        - size: the size of the batch. Default is the variable batch_size declared\n","            at the start of the code.\n","\n","    Returns:\n","        - batch: a tensor of the batch of random images appended in the order they were fetched in.\n","        - lengths: the length of each image fetched, in the order they were fetched in.\n","    \"\"\"\n","\n","    batch_ids = np.random.choice(len(data), size)\n","    batch_images = [data[id] for id in batch_ids]\n","    lengths = [len(image) for image in batch_images]\n","    strokes = []\n","    for image in batch_images:\n","        new_image = np.zeros((Nmax, 3))\n","        new_image[:len(image), :] = image[:len(image), :] # copy over values\n","        strokes.append(new_image)\n","\n","    encoded_strokes = np.stack(encode_dataset1(np.array(strokes),lengths), 1) # don't forget to stack input along dim = 1\n","    batch = torch.from_numpy(encoded_strokes.astype(float))\n","    return batch, torch.tensor(lengths)"]},{"cell_type":"code","execution_count":65,"metadata":{"execution":{"iopub.execute_input":"2024-02-08T00:40:20.172475Z","iopub.status.busy":"2024-02-08T00:40:20.171922Z","iopub.status.idle":"2024-02-08T00:40:20.675489Z","shell.execute_reply":"2024-02-08T00:40:20.674514Z","shell.execute_reply.started":"2024-02-08T00:40:20.172445Z"},"trusted":true},"outputs":[],"source":["class Encoder(nn.Module):\n","    def __init__(self):\n","        super(Encoder, self).__init__()\n","        self.lstm = nn.LSTM(stroke_dim + Nclass, enc_hidden_dim, bidirectional=True)\n","\n","        self.fc_mu = nn.Linear(2*enc_hidden_dim, latent_dim)\n","        self.fc_sigma = nn.Linear(2*enc_hidden_dim, latent_dim)\n","\n","    def forward(self, x):\n","        \"\"\"\n","        Runs a batch of images through the encoder and returns its latent vector.\n","        Does not normalize values on its own.\n","\n","        Parameters:\n","         - x: Tensor of shape [max_strokes, batch_size, num_features]\n","            where max_strokes is the highest number of points possible for an image in the batch.\n","            x should be normalized.\n","        - batch_size: int representing the current batch size.\n","\n","        Returns:\n","        - mu: Tensor of shape [batch_size, 2*hidden dim] representing the mean of the distribution of values\n","        - sigma: Tensor of shape [batch_size, 2*hidden dim] representing the log of the distribution of values\n","        \"\"\"\n","\n","        # Get the hidden states\n","        hidden, cell = torch.zeros(2, x.shape[1], enc_hidden_dim,device=device), torch.zeros(2, x.shape[1], enc_hidden_dim,device=device)\n","\n","        _, (hidden, cell) = self.lstm(x.float(), (hidden, cell))\n","        hidden_forward_dir, hidden_backward_dir = torch.split(hidden, 1, 0)\n","        hidden_concatenated = torch.cat([hidden_forward_dir.squeeze(0), hidden_backward_dir.squeeze(0)], 1)\n","\n","        mu = self.fc_mu(hidden_concatenated)\n","        sigma = self.fc_sigma(hidden_concatenated)\n","        return mu, sigma\n","\n","encoder = Encoder()"]},{"cell_type":"code","execution_count":66,"metadata":{"execution":{"iopub.execute_input":"2024-02-08T00:40:20.677050Z","iopub.status.busy":"2024-02-08T00:40:20.676689Z","iopub.status.idle":"2024-02-08T00:40:20.684830Z","shell.execute_reply":"2024-02-08T00:40:20.683896Z","shell.execute_reply.started":"2024-02-08T00:40:20.677020Z"},"trusted":true},"outputs":[],"source":["def distribution(decoder_output):\n","    \"\"\"\n","    Input: \n","        decoder_output (6M + 3): Decoder LSTM output\n","    Return:\n","        mixture_weights (M): Mixture weights (probability of a point being in distribution i)\n","        mean_x (M): The x-values of the means of each distribution\n","        mean_y (M): The y-values of the means of each distribution\n","        std_x (M): The standard deviations of the x-values\n","        std_y (M): The standard deviations of the y-values\n","        corr_xy (M): The correlation coefficients of the x and y values\n","        q (3): The predicted pen state (pen_down, pen_up, <EOS>)\n","    \"\"\"\n","    # Split the decoder output into \n","    # [pi, mean_x, mean_y, std_x, std_y, rho_xy] and [q1,q2,q3]\n","    parameters = torch.split(decoder_output, 6, 2)\n","\n","    # Chunk the parameters together, then stack them \n","    # so that each column defines a distribution\n","    mixture_parameters = torch.stack(parameters[:-1],1)\n","\n","    # Split mixture parameters into each parameter\n","    mixture_weights, mean_x, mean_y, std_x, std_y, corr_xy = torch.split(mixture_parameters, 1, 3)\n","\n","    # The 3 leftover parameters are for the pen state\n","    pen_state = parameters[-1]\n","\n","    mixture_weights = F.softmax(mixture_weights/T,dim=3)\n","    std_x = torch.exp(std_x)*sqrtT\n","    std_y = torch.exp(std_y)*sqrtT\n","    corr_xy = F.tanh(corr_xy)\n","    pen_state = F.softmax(pen_state/T,dim=2)\n","\n","    return mixture_weights, mean_x, mean_y, std_x, std_y, corr_xy, pen_state"]},{"cell_type":"code","execution_count":67,"metadata":{"execution":{"iopub.execute_input":"2024-02-08T00:40:20.686103Z","iopub.status.busy":"2024-02-08T00:40:20.685824Z","iopub.status.idle":"2024-02-08T00:40:20.699548Z","shell.execute_reply":"2024-02-08T00:40:20.698738Z","shell.execute_reply.started":"2024-02-08T00:40:20.686071Z"},"trusted":true},"outputs":[],"source":["def gaussian_mixture_model(mixture_weights, mean_x, mean_y, std_x, std_y, corr_xy):\n","    \"\"\"\n","    Input:\n","        mixture_weights: Mixture weights (probability of a point being in distribution i)\n","        mean_x: The x-values of the means of each distribution\n","        mean_y: The y-values of the means of each distribution\n","        std_x: The standard deviations of the x-values\n","        std_y: The standard deviations of the y-values\n","        corr_xy: The correlation coefficients of the x and y values\n","        \n","    Return: \n","        The sampled x and y offsets\n","    \"\"\"\n","    # Choose which distribution to sample from\n","    mixture_weights = mixture_weights.squeeze().transpose(0, 1).contiguous() \n","     \n","    # Index for each batch\n","    i = torch.searchsorted(mixture_weights.cumsum(0), torch.rand(batch_size, 1)).squeeze()\n","    \n","    # Sample from bivariate normal distribution i\n","    rand_x, rand_y = torch.randn(batch_size), torch.randn(batch_size)\n","    \n","    mean_x = torch.take(mean_x, i)\n","    mean_y = torch.take(mean_y, i)\n","    std_x = torch.take(std_x, i)\n","    std_y = torch.take(std_y, i)\n","    corr_xy = torch.take(corr_xy, i)\n","    \n","    # Alternatively torch.distributions.multivariate_normal.MultivariateNormal?\n","    offset_x = mean_x + std_x * rand_x\n","    offset_y = mean_y + std_y * (corr_xy * offset_x + torch.sqrt(1 - corr_xy ** 2) * rand_y)\n","    return offset_x.unsqueeze(0), offset_y.unsqueeze(0)"]},{"cell_type":"code","execution_count":68,"metadata":{"execution":{"iopub.execute_input":"2024-02-08T00:40:20.701470Z","iopub.status.busy":"2024-02-08T00:40:20.700694Z","iopub.status.idle":"2024-02-08T00:40:20.713985Z","shell.execute_reply":"2024-02-08T00:40:20.713072Z","shell.execute_reply.started":"2024-02-08T00:40:20.701439Z"},"trusted":true},"outputs":[],"source":["def sample(mixture_weights, mean_x, mean_y, std_x, std_y, corr_xy, pen_state):\n","    offset_x, offset_y = gaussian_mixture_model(mixture_weights, mean_x, mean_y, std_x, std_y, corr_xy)\n","    \n","    pen_state = pen_state.squeeze()\n","    pen_state = torch.searchsorted(pen_state.cumsum(1), torch.rand(batch_size, 1)).squeeze()\n","    assert(pen_state[0].item() <= 2 and pen_state[1].item() <= 2)\n","    next_point = torch.cat((offset_x, offset_y, torch.zeros(3, batch_size)))\n","    next_point = torch.cat((offset_x, offset_y, torch.eye(3)[pen_state].transpose(0, 1)))\n","    \n","    return next_point.transpose(0, 1)"]},{"cell_type":"code","execution_count":69,"metadata":{"execution":{"iopub.execute_input":"2024-02-08T00:40:20.715432Z","iopub.status.busy":"2024-02-08T00:40:20.715162Z","iopub.status.idle":"2024-02-08T00:40:20.726434Z","shell.execute_reply":"2024-02-08T00:40:20.725657Z","shell.execute_reply.started":"2024-02-08T00:40:20.715410Z"},"trusted":true},"outputs":[],"source":["input_dim = latent_dim + stroke_dim + Nclass# z | (x,y,p1,p2,p3) | (c1, c2, ... c_Nclass)\n","output_dim = 6*M + 3\n","\n","class Decoder(nn.Module):\n","    def __init__(self):\n","        super(Decoder, self).__init__()\n","\n","        # generates initial hidden and cell states from latent vector\n","        self.fc_in = nn.Linear(latent_dim,2*dec_hidden_dim)\n","\n","        # Fully connected layer for reducing dimensionality of hidden state before\n","        # being used for distribution parameters.\n","        self.fc_proj = nn.Linear(dec_hidden_dim,output_dim)\n","\n","        # Input has dimension latent_dim + 5 for latent vector and initial stroke\n","        self.lstm = nn.LSTM(input_dim,dec_hidden_dim)\n","    \n","    def forward(self, z, stroke):\n","        \"\"\"\n","        Parameters:\n","            z - Tensor of size  (batch_size, latent_dim), with latent vector samples.\n","\n","            stroke - Tensor of size (batch_size, stroke dim); previous stroke\n","\n","\n","        Returns:\n","            Tensor of size (N_max, batch_size, stroke dim), as the next stroke\n","        \"\"\"\n","        \n","        hidden, cell = torch.split(\n","            F.tanh(self.fc_in(z).unsqueeze(0)),\n","            [dec_hidden_dim, dec_hidden_dim],\n","            dim = 2)\n","\n","        out, (hidden, cell) = self.lstm(stroke.float(),(hidden.contiguous(), cell.contiguous()))\n","        \n","        params = distribution(self.fc_proj(out))\n","        \n","        return [i[1:] for i in params]"]},{"cell_type":"code","execution_count":70,"metadata":{"execution":{"iopub.execute_input":"2024-02-08T00:40:20.729710Z","iopub.status.busy":"2024-02-08T00:40:20.727407Z","iopub.status.idle":"2024-02-08T00:40:20.742319Z","shell.execute_reply":"2024-02-08T00:40:20.741429Z","shell.execute_reply.started":"2024-02-08T00:40:20.729680Z"},"trusted":true},"outputs":[],"source":["def bivariate_normal_pdf(dx, dy, mu_x, mu_y, std_x, std_y, corr_xy):\n","    \"\"\"\n","    Return N(dx, dy | mu_x, mu_y, std_x, std_y, corr_xy)\n","    \"\"\"\n","    z_x = (dx - mu_x) / std_x\n","    z_y = (dy - mu_y) / std_y\n","    exponent = -(z_x ** 2 - 2 * corr_xy * z_x * z_y + z_y ** 2) / (2 * (1 - corr_xy ** 2))\n","    norm = 2 * np.pi * std_x * std_y * torch.sqrt(1-corr_xy ** 2)\n","    return torch.exp(exponent) / norm\n","\n","\n","def offset_reconstruction_loss(dx, dy, pi, mu_x, mu_y, std_x, std_y, corr_xy, mask):\n","    \"\"\"\n","    pi: The mixture probabilities\n","    mask: 1 if the point is not after the final stroke, 0 otherwise\n","\n","    Returns the reconstruction loss for the strokes, L_s\n","    \"\"\"\n","    pdf = bivariate_normal_pdf(dx, dy, mu_x, mu_y, std_x, std_y, corr_xy)\n","    \n","    return -torch.sum(mask[1:] * torch.log(1e-5 + torch.sum(pi*pdf,axis=0))) / (batch_size*Nmax) \n","\n","\n","def pen_reconstruction_loss(input_pen_state, output):\n","    \"\"\"\n","    Parameters:\n","\n","        N_max (int) - Maximum sketch sequence length\n","        \n","        input_pen_state (batch_size,3) - Pen state data for a stroke\n","\n","        output (batch_size, 3)- Generated pen state logit values.\n","\n","    Returns:\n","        Reconstruction loss for pen state.\n","    \"\"\"    \n","\n","    return -torch.sum(input_pen_state*torch.log(1e-5+output)) / (batch_size*Nmax)"]},{"cell_type":"code","execution_count":71,"metadata":{"execution":{"iopub.execute_input":"2024-02-08T00:40:20.744260Z","iopub.status.busy":"2024-02-08T00:40:20.743570Z","iopub.status.idle":"2024-02-08T00:40:20.758010Z","shell.execute_reply":"2024-02-08T00:40:20.757161Z","shell.execute_reply.started":"2024-02-08T00:40:20.744229Z"},"trusted":true},"outputs":[],"source":["class VAE(nn.Module):\n","    def __init__(self):\n","        super(VAE, self).__init__()\n","        self.encoder = Encoder()\n","        self.decoder = Decoder()\n","    \n","    def forward(self, batch, lengths): \n","        batch = batch.to(device)\n","        lengths = lengths.to(device)\n","\n","        optimizer.zero_grad()\n","        \n","        mean, logvar = self.encoder(batch)\n","        \n","        random_sample = torch.randn(batch_size, latent_dim, device = device)\n","        std = torch.exp(logvar/2) # logvar / 2 should be a float\n","        z = mean + std*random_sample\n","        \n","        empty = torch.zeros(stroke_dim + Nclass)\n","        empty[2] = 1\n","        \n","        start_stroke = torch.stack([empty] * batch_size).unsqueeze(0).to(device)\n","        strokes = torch.cat([start_stroke, batch], 0)\n","        \n","        zs = torch.stack([z] * (Nmax+1))\n","        \n","        strokes = torch.cat([strokes,zs], 2)\n","        \n","        params = self.decoder(z, strokes)\n","        \n","        mask, dx, dy, p = make_target(batch, lengths)\n","        \n","        l_p = pen_reconstruction_loss(p, params[6])\n","        \n","        offset_params = [params[i].squeeze().transpose(0, 1) for i in range(6)]\n","        l_s = offset_reconstruction_loss(dx, dy, *offset_params, mask)\n","        \n","        l_r = l_p + l_s\n","        \n","        l_kl = kl_loss(mean, logvar)\n","        \n","        loss = l_r + w_kl * l_kl\n","        \n","        loss.backward()\n","        \n","        grad_threshold = 1.0 # tunable parameter, prevents exploding gradient\n","        nn.utils.clip_grad_norm_(model.encoder.parameters(), grad_threshold)\n","        nn.utils.clip_grad_norm_(model.decoder.parameters(), grad_threshold)\n","\n","        # update encoder and decoder parameters using adam algorithm\n","        optimizer.step()\n","        \n","        output = torch.zeros(Nmax, batch_size, 5,device=device)\n","        with torch.device(device):\n","            for i in range(Nmax):\n","                output[i] = sample(*[j[i] for j in params])\n","        \n","        return output, loss, l_kl, l_s, l_p"]},{"cell_type":"code","execution_count":72,"metadata":{"execution":{"iopub.execute_input":"2024-02-08T00:40:20.759394Z","iopub.status.busy":"2024-02-08T00:40:20.759109Z","iopub.status.idle":"2024-02-08T00:40:20.771892Z","shell.execute_reply":"2024-02-08T00:40:20.771143Z","shell.execute_reply.started":"2024-02-08T00:40:20.759361Z"},"trusted":true},"outputs":[],"source":["def make_target(batch, lengths):\n","    with torch.device(device):\n","        mask = torch.zeros((Nmax + 1, batch.size()[1]))\n","        for index, num_strokes in enumerate(lengths):\n","            mask[:num_strokes, index] = 1\n","\n","        dx = batch[:, :, 0]\n","        dy = batch[:, :, 1]\n","        # copy + append together pen state values\n","        p = torch.stack([batch.data[:, :, 2], batch.data[:, :, 3], batch.data[:, :, 4]], 2)\n","\n","        return mask, dx, dy, p"]},{"cell_type":"code","execution_count":73,"metadata":{"execution":{"iopub.execute_input":"2024-02-08T01:12:09.578577Z","iopub.status.busy":"2024-02-08T01:12:09.578216Z","iopub.status.idle":"2024-02-08T01:12:09.584801Z","shell.execute_reply":"2024-02-08T01:12:09.583896Z","shell.execute_reply.started":"2024-02-08T01:12:09.578548Z"},"trusted":true},"outputs":[],"source":["def save_model():\n","    '''\n","    Saves model parameters to \"model/temp\".  An epoch is saved as t_{n}, where\n","    n enumerates the parameter files.  Note that these get VERY big.   \n","    '''\n","    \n","    dir = \"model/\"\n","    \n","    if not os.path.isdir(dir):\n","        os.mkdir(dir)\n","    \n","    filename = f\"{str(datetime.now())}.pt\"\n","    files = os.listdir(dir)\n","    \n","    while len(files) >= 3:\n","        os.remove(dir + files.pop(0))\n","        \n","    torch.save({\n","            \"model\": model.state_dict(),\n","            \"opt\": optimizer.state_dict()\n","        }, dir + filename)"]},{"cell_type":"code","execution_count":74,"metadata":{"execution":{"iopub.execute_input":"2024-02-08T00:40:20.788190Z","iopub.status.busy":"2024-02-08T00:40:20.787844Z","iopub.status.idle":"2024-02-08T00:40:24.435417Z","shell.execute_reply":"2024-02-08T00:40:24.434401Z","shell.execute_reply.started":"2024-02-08T00:40:20.788166Z"},"trusted":true},"outputs":[],"source":["train_dataset = SketchesDataset(\n","        datasets=[dataset1, dataset2],\n","        mode='train',\n","        transform=make_image\n","    )\n","test_dataset = SketchesDataset(\n","        datasets=[dataset1, dataset2],\n","        mode='test',\n","        transform=make_image\n","    )\n","train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"]},{"cell_type":"code","execution_count":75,"metadata":{"execution":{"iopub.execute_input":"2024-02-08T00:40:24.436998Z","iopub.status.busy":"2024-02-08T00:40:24.436677Z","iopub.status.idle":"2024-02-08T00:40:24.441807Z","shell.execute_reply":"2024-02-08T00:40:24.440963Z","shell.execute_reply.started":"2024-02-08T00:40:24.436973Z"},"trusted":true},"outputs":[],"source":["#next(iter(train_dataloader))"]},{"cell_type":"code","execution_count":76,"metadata":{"execution":{"iopub.execute_input":"2024-02-08T00:40:24.444141Z","iopub.status.busy":"2024-02-08T00:40:24.443828Z","iopub.status.idle":"2024-02-08T00:40:24.453898Z","shell.execute_reply":"2024-02-08T00:40:24.453167Z","shell.execute_reply.started":"2024-02-08T00:40:24.444119Z"},"trusted":true},"outputs":[],"source":["def train():\n","    print(\"Training loop running...\\n\")\n","\n","    for epoch in range(n_epochs):\n","        for step, (batch, lengths) in enumerate(tqdm(train_dataloader)):\n","            batch = batch.squeeze(2).transpose(0, 1)\n","            output, loss, l_kl, l_s, l_p = model(batch, lengths)\n","\n","            if step % 100 == 0:\n","                print(f\"Epoch: {epoch + 1}, Step: {step + 1}, Loss: {loss.item()}\")\n","                print(f\"l_kl: {l_kl:.4f} l_s: {l_s:.4f} l_p: {l_p:.4f}\") \n","                print(\"---------------------------------------------------------\\n\")\n","\n","            if epoch % 500 == 0:\n","                 save_model()\n","\n","            if step % 100 == 0:\n","                # draw image\n","                display_encoded_image(output[:, 0, :])\n","                display_encoded_image(batch[:, 0, :])"]},{"cell_type":"code","execution_count":77,"metadata":{"execution":{"iopub.execute_input":"2024-02-08T00:40:24.455251Z","iopub.status.busy":"2024-02-08T00:40:24.454983Z","iopub.status.idle":"2024-02-08T01:06:00.426151Z","shell.execute_reply":"2024-02-08T01:06:00.424615Z","shell.execute_reply.started":"2024-02-08T00:40:24.455229Z"},"trusted":true},"outputs":[{"ename":"RuntimeError","evalue":"CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[77], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[39m=\u001b[39m VAE()\u001b[39m.\u001b[39;49mto(device)\n\u001b[1;32m      2\u001b[0m optimizer \u001b[39m=\u001b[39m Adam(model\u001b[39m.\u001b[39mparameters(), lr \u001b[39m=\u001b[39m lr)    \n\u001b[1;32m      4\u001b[0m \u001b[39m#if pretrained and not len(os.listdir(\"model/final\")) == 0:\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m#    weights = os.listdir(\"model/final\")\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39m#    loaded_state = torch.load(f\"model/final/{weights[0]}\", map_location=device)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39m#    model.load_state_dict(loaded_state['model'])\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[39m#    optimizer.load_state_dict(loaded_state['opt'])\u001b[39;00m\n","File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1160\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1158\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1160\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n","File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[39mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    812\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n","File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[39mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    812\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n","File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/rnn.py:213\u001b[0m, in \u001b[0;36mRNNBase._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn, recurse\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m--> 213\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_apply(fn, recurse)\n\u001b[1;32m    215\u001b[0m     \u001b[39m# Resets _flat_weights\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[39m# Note: be v. careful before removing this, as 3rd party device types\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[39m# likely rely on this behavior to properly .to() modules like LSTM.\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_flat_weights()\n","File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:833\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    830\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    831\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    832\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 833\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[1;32m    834\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    835\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n","File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1158\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1155\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[1;32m   1156\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1158\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"]}],"source":["model = VAE().to(device)\n","optimizer = Adam(model.parameters(), lr = lr)    \n","    \n","#if pretrained and not len(os.listdir(\"model/final\")) == 0:\n","#    weights = os.listdir(\"model/final\")\n","#    loaded_state = torch.load(f\"model/final/{weights[0]}\", map_location=device)\n","#    model.load_state_dict(loaded_state['model'])\n","#    optimizer.load_state_dict(loaded_state['opt'])\n","\n","train()"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":22085,"sourceId":28618,"sourceType":"datasetVersion"}],"dockerImageVersionId":30646,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"}},"nbformat":4,"nbformat_minor":4}
